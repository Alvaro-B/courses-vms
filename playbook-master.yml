---
- name: Playbook curso 
  hosts: all
  become: true
  vars:
    restart: no

    # USUARIO
    base_username: alumno
    shell: "bash"

    # Extra software
    extras: []

    # Versións xenerais
    java_main_version: 21

    # Definir SW máquina
    common_conf: yes 
    oh_my_zsh: no
    browsers: yes
    java: no # TODO: Correxir tarefa para definir java como default
    vsc: yes
    jupyter: yes
    rdp: yes 
    # == STS ==
    # Consultar versións: 
    # https://github.com/spring-projects/spring-tools/wiki/Previous-Versions
    spring: no
    sts_major_version: 4
    sts_version: '4.32.0.RELEASE'
    sts_distribution: 'e4.37'
    sts_openjdk_version: "{{ java_main_version }}"
    # ============================================
    # 
    # == Maven ==
    maven: no
    maven_v: 3.9.11
    maven_java_version: "{{ java_main_version }}"
    # ===========================================
    # 
    # == Docker ==
    docker: no
    docker_compose_version: v2.39.4
    # ===========================================
    # 
    # == Apache Hive ==
    # Ó instalarse Hive, automáticamente, instálase Hadoop
    # Para evitar configuracións erroneas, instalar Hadoop mediante o rol de Hive.
    hive: no
    hive_version: 4.1.0
    hive_hadoop_v: 3.4.1
    hive_openjdk_version: 17

    # ===========================================
    interfaces_red: no
    copy_workspace: yes
    # == Downloads ==
    download_resources: no
    downloads_urls:
      - https://artifacts.elastic.co/downloads/kibana/kibana-8.13.0-linux-x86_64.tar.gz
      - https://artifacts.elastic.co/downloads/kibana/kibana-8.13.0-x86_64.rpm
      - https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.13.0-linux-x86_64.tar.gz
      - https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.13.0-x86_64.rpm
      - https://artifacts.elastic.co/downloads/logstash/logstash-8.13.0-linux-x86_64.tar.gz
      - https://artifacts.elastic.co/downloads/logstash/logstash-8.13.0-x86_64.rpm
      - https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.13.0-linux-x86_64.tar.gz
      - https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.13.0-x86_64.rpm
      - https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-8.13.0-linux-x86_64.tar.gz
      - https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-8.13.0-x86_64.rpm
    # ============================================================================================
    #
    
    nodejs: no     
    eclipse: no
    pycharm: no    
    postman: no

    eclipse_rel: '2025-03'
    eclipse_v: 'R'
    node_version: 22
    pycharm_v: '2025.2.2'
    tomcat_version: 9.0.84
    tomcat_major_version: 9

  tasks:   

    # TODO: revisar sw base para Fedora (eliminar innecesario cursos)
    - name: Configuración común
      include_role:
        name: common
      vars:
        # Definir url do repositorio fedora.repo e fedora-updates.repo
        # {{ mirror }}/updates/$releasever/Everything/$basearch/
        change_mirror: no
        mirror: https://fr2.rpmfind.net/linux/fedora/linux 
        username: "{{ base_username }}"
        user_shell: "{{ shell }}"
        common_selinux_state: disabled
        disable_zram: false
        extra_software: "{{ extras }}"
        disable_keyring: yes
      when: common_conf 
    
    - name: Instala Oh-My-Zsh
      include_role: 
        name: oh-my-zsh
      vars:
        username: "{{ base_username }}"
      when: oh_my_zsh

    # TODO: Acceso directo Firefox
    - name: Instala Navegadores 
      block:
          - name: Instala Firefox
            include_role:
              name: firefox
            vars:
              browser_configuration_files: no 
          
          - name: Instala Google Chrome
            include_role:
              name: google_chrome
            vars:
              chrome_owner: "{{ base_username }}"
              browser_configuration_files: no
      when: browsers

    - name: Instala Java
      include_role:
        name: java
      vars:
        # Solo se soporta openjdk
        java_option: openjdk
        java_openjdk_version: "{{ java_main_version }}"        
        # Crea el fichero java_ansible.sh apuntando a la versión de java instalada.
        java_set_java_home: true
        # Versión de java que se va a usar por defecto en la consola shell
        java_set_default: true
      when: java
    
    # TODO: Acceso directo VSC
    - name: Instala Visual Studio Code
      include_role:
        name: visual_studio_code
      when: vsc

    - name: Rol jupyter notebook
      include_role:
        name: jupyter_notebook
      vars:
        jupyter_notebook_owner: "{{ base_username }}"
        jupyter_notebook_r: false
        jupyter_notebook_pyspark: true
        jupyter_notebook_pyspark_auto: false
      when: jupyter

    # Instalación de RDP 
    # Conectarse á máquina a través do porto 3389
    # Precisa reiniciar ou iniciar sesión unha vez para que funcione.
    - name: Instalar RDP
      include_role:
        name: rdp
      vars:
        rdp_owner: "{{ base_username }}"
        rdp_users: []
      when: rdp

    - name: Instalar Spring Tool Suite
      include_role:
        name: spring_tool_suite
      vars:
        spring_tool_suite_major_version: "{{ sts_major_version }}"
        spring_tool_suite_version: "{{ sts_version }}"
        spring_tool_suite_distribution: "{{ sts_distribution }}"
        spring_tool_suite_owner: "{{ base_username }}"
        spring_tool_suite_java_option: openjdk
        spring_tool_suite_openjdk_version: "{{ sts_openjdk_version }}"
      when: spring

    - name: Instalar Maven
      include_role:
        name: maven
      vars:
        maven_version: "{{ maven_v }}" 
        maven_java_option: openjdk
        maven_openjdk_version: "{{ maven_java_version }}"
      when: maven

    - name: Instalar Docker
      include_role:
        name: docker
      vars:
        docker_authorized_user: "{{ base_username }}"
        docker_compose_install: true
        docker_compose_version: "{{ docker_compose_version }}"
      when: docker

    - name: Instalar Apache Hive
      include_role:
        name: apache_hive
      vars:
        apache_hive_version: "{{ hive_version }}"
        apache_hive_owner: "{{ base_username }}"
        apache_hive_hadoop_version: "{{ hive_hadoop_v }}"
        apache_hive_java_option: openjdk
        apache_hive_openjdk_version: "{{ hive_openjdk_version }}"
      when: hive

    - name: Rol Interfaces
      include_role:
        name: interfaces
      when: interfaces_red

    - name: Copiar workspace
      copy:
        src: /vagrant/workspace
        dest: /home/{{ base_username }}
        owner: "{{ base_username }}"
        group: "{{ base_username }}"
        mode: '0755'
        remote_src: yes
      when: copy_workspace

    - name: Downloads
      block:
        - name: Crea directorio Downloads
          file:
            path: /home/{{ base_username }}/Downloads
            owner: "{{ base_username }}"
            group: "{{ base_username }}"
            state: directory
            mode: 0755

        - name: Download software
          get_url:
            url: "{{ item }}"
            dest: /home/{{ base_username }}/Downloads
            owner: "{{ base_username }}"
            group: "{{ base_username }}"
            mode: 0755
          loop: "{{ downloads_urls }}"
      when: download_resources

    - name: Add elasticsearch repo
      yum_repository:
        name: elasticsearch
        description: Repository for Elasticsearch
        baseurl: "https://artifacts.elastic.co/packages/8.x/yum"
        gpgcheck: yes
        gpgkey: "https://artifacts.elastic.co/GPG-KEY-elasticsearch"
        enabled: yes

    - name: Reiniciar
      reboot:
      when: restart
    
# ============================================================================
    - name: Instalación de Node JS
      include_role:
        name: nodejs
      vars:
        nodejs_version: "{{ node_version }}"
      when: nodejs

    # Descarga e instala el eclipse para cualquier versión. Solo necesitamos indicar la release que queremos.
    - name: Instalación de Eclipse
      include_role:
        name: eclipse
      vars:
        eclipse_release: "{{ eclipse_rel }}" 
        eclipse_owner: "{{ base_username }}"
        # Si necesitamos cualquier plugin de estos tres, se definen a true y se instalan automáticamente. Solo se han probado en versiones modernas de eclipse.
        install_oepe: false
        install_jboss_tools: false
        # Pasa los parámetros al rol de java.
        # El eclipse 2020 no admite java 8
        eclipse_java_option: openjdk
        eclipse_openjdk_version: "{{ java_main_version }}"
        eclipse_version: "{{eclipse_v}}"
      when: eclipse

    - name: Instalar PyCharm
      include_role:
        name: pycharm
      vars:
        pycharm_version: "{{ pycharm_v }}"
        pycharm_owner: "{{ base_username }}"
      when: pycharm

    - name: Instalación de Postman
      include_role:
        name: postman
      vars:
        postman_version: latest
        postman_owner: "{{ base_username }}"
      when: postman

    # # Instalación de Hadoop
    # - name: Instalación de Hadoop
    #   include_role:
    #     name: hadoop
    #   vars:
    #     # Las versiones de Hadoop se van deprecando y eliminan las descargas anteriores. 
    #     # Yendo a la URL: http://apache.rediris.es/hadoop/common/ está la lista de versiones descargables.
    #     hadoop_version: 3.3.2
    #     hadoop_owner: "{{ base_username }}"
    #     hadoop_java_option: openjdk
    #     hadoop_openjdk_version: 1.8.0

    # Posee dependencia con Hadoop. Al instalarse Hive automáticamente se instala hadoop para registrarse.
    # Para evitar configuraciones erroneas, es mejor instalar solo Hive y así ya se instala la versión correcta de Hadoop.
    # WARNING -> Todavía no es compatible con Java 11 y no se puede aislar la versión de java con hive hasta la versión 3.2.X
    # - name: Instalación de Apache Hive
    #   include_role:
    #     name: apache_hive
    #   vars:
    #     apache_hive_version: 3.1.2
    #     apache_hive_owner: "{{ base_username }}"
    #     apache_hive_hadoop_version: 3.3.0
    #     apache_hive_java_option: openjdk
    #     apache_hive_openjdk_version: 1.8.0
    

   
    